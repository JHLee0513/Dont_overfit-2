{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrowed from Preston and implemented as needed\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Activation, AlphaDropout, Input, Add, Concatenate\n",
    "from keras.activations import selu\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam, RMSprop, Adamax, SGD, Nadam\n",
    "from keras.losses import logcosh\n",
    "from clr import CyclicLR\n",
    "import keras.backend as K\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN:\n",
    "    '''\n",
    "    Small SNN for medical data prediction.\n",
    "    Usage:\n",
    "        snn = SNN(input_shape)\n",
    "        model = snn.create_model()\n",
    "        model.train...\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.max_label = 0.0\n",
    "\n",
    "    def create_model(self) -> Model:\n",
    "        '''\n",
    "        Creates model. Returns Keras Model object.\n",
    "        Model follow simple encoder-decoder structure.\n",
    "        Uses SELU to self-regularize without batch-normalization.\n",
    "        Treats all values in batch as single, flattened array of values.        \n",
    "        '''\n",
    "        input_tensor = Input(self.input_shape)\n",
    "        x = input_tensor\n",
    "        starting_neurons = 2048\n",
    "        starting_alpha = 0.025\n",
    "        decay = 0.6\n",
    "        alpha_decay = 0.6\n",
    "        layers = 3\n",
    "\n",
    "        # skip_conn = []\n",
    "        # for i in range(layers):\n",
    "        #     x = Dense(int(starting_neurons * math.pow(decay, i)))(x)\n",
    "        #     x = self.selu_layer(x, int(\n",
    "        #         starting_neurons * math.pow(decay, i)), starting_alpha * math.pow(alpha_decay, i))\n",
    "        #     skip_conn.append(x)\n",
    "        # latent = self.selu_layer(\n",
    "        #     x, int(starting_neurons * math.pow(decay, layers - 1)))\n",
    "        # x = latent\n",
    "        # for i in range(layers):\n",
    "        #     p = layers - i - 1\n",
    "        #     x = Dense(int(starting_neurons * math.pow(decay, p)))(x)\n",
    "        #     x = self.selu_layer(x, int(starting_neurons * math.pow(decay, p)))\n",
    "        #     x = Add()([x, skip_conn.pop()])\n",
    "        for i in range(layers):\n",
    "            x = Dense(int(starting_neurons * math.pow(decay, i)), kernel_initializer=\"lecun_normal\")(x)\n",
    "            x = self.selu_layer(x,int(starting_neurons * math.pow(decay, i)), starting_alpha * math.pow(alpha_decay, i))\n",
    "        x = Dense(25, kernel_initializer=\"lecun_normal\")(x)\n",
    "        latent = self.selu_layer(x, 25, 0.0)\n",
    "        x = Activation(selu,name='latent')(latent) \n",
    "        # x = Dense(self.input_shape[0], kernel_initializer=\"lecun_normal\")(x)\n",
    "        # Reconstruction loss\n",
    "        recon = Dense(\n",
    "            self.input_shape[1], kernel_initializer=\"lecun_normal\", name=\"r\")(x)\n",
    "        # Single unit linear layer for output\n",
    "        x = Dense(16, kernel_initializer='lecun_normal', activation=selu)(latent)\n",
    "        x = Dense(16, kernel_initializer='lecun_normal', activation=selu)(x)\n",
    "        x = Dense(16, kernel_initializer='lecun_normal')(x)\n",
    "\n",
    "        x = Dense(1, kernel_initializer='lecun_normal', name=\"x\")(x)\n",
    "        # x = Concatenate()([x, recon])\n",
    "\n",
    "        model = Model(inputs=input_tensor, outputs=[x, recon])\n",
    "        model.compile(loss='logcosh',\n",
    "                      optimizer=RMSprop(lr=0), loss_weights=[.1, 100])#, metrics=[self.label, self.recon])\n",
    "        return model\n",
    "\n",
    "    def selu_layer(self, x, units, rate:float=0):\n",
    "        a = Activation(selu)(x)\n",
    "        a = Dense(units, kernel_initializer='lecun_normal')(x)\n",
    "\n",
    "\n",
    "        a = Dense(units, kernel_initializer='lecun_normal')(a)\n",
    "        # Heavy regularization due to small sample sizes\n",
    "        a = AlphaDropout(rate)(a)\n",
    "        a = Add()([a, x])\n",
    "\n",
    "\n",
    "        return a\n",
    "\n",
    "    def dynamic_recon_loss(self, y_true, y_pred):\n",
    "        label_error = self.label(y_true, y_pred)\n",
    "        recon_error = self.recon(y_true, y_pred)\n",
    "\n",
    "        return label_error * recon_error\n",
    "\n",
    "    def recon(self, y_true, y_pred):\n",
    "        # Split stuff\n",
    "        recon_true = y_true[:, 1:]\n",
    "        recon_pred = y_pred[:, 1:]\n",
    "\n",
    "        recon_error = logcosh(recon_true, recon_pred)\n",
    "\n",
    "        return recon_error\n",
    "\n",
    "    def label(self, y_true, y_pred):\n",
    "        # Split stuff\n",
    "        label_true = y_true[:, 0]\n",
    "        label_pred = y_pred[:, 0]\n",
    "        label_error = logcosh(label_true, label_pred)\n",
    "\n",
    "        return label_error\n",
    "\n",
    "    def earlystopping(self, patience=10):\n",
    "        return EarlyStopping(\"recon\", patience=patience, restore_best_weights=True)\n",
    "    def clr(self):\n",
    "        return CyclicLR(base_lr=7e-5, max_lr=6e-4, step_size=200, mode=\"triangular2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (300,1)\n",
    "snn = SNN(input_shape)\n",
    "model = snn.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 1, 300)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_106 (Dense)               (None, 1, 2048)      616448      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 1, 2048)      4196352     dense_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 1, 2048)      4196352     dense_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_29 (AlphaDropout) (None, 1, 2048)      0           dense_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 1, 2048)      0           alpha_dropout_29[0][0]           \n",
      "                                                                 dense_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 1, 1228)      2516172     add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 1, 1228)      1509212     dense_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_111 (Dense)               (None, 1, 1228)      1509212     dense_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_30 (AlphaDropout) (None, 1, 1228)      0           dense_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 1, 1228)      0           alpha_dropout_30[0][0]           \n",
      "                                                                 dense_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_112 (Dense)               (None, 1, 737)       905773      add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 1, 737)       543906      dense_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 1, 737)       543906      dense_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_31 (AlphaDropout) (None, 1, 737)       0           dense_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 1, 737)       0           alpha_dropout_31[0][0]           \n",
      "                                                                 dense_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 1, 25)        18450       add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_116 (Dense)               (None, 1, 25)        650         dense_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 1, 25)        650         dense_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_32 (AlphaDropout) (None, 1, 25)        0           dense_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 1, 25)        0           alpha_dropout_32[0][0]           \n",
      "                                                                 dense_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 1, 16)        416         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, 1, 16)        272         dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 1, 16)        272         dense_119[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "latent (Activation)             (None, 1, 25)        0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x (Dense)                       (None, 1, 1)         17          dense_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "r (Dense)                       (None, 1, 300)       7800        latent[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 16,565,860\n",
      "Trainable params: 16,565,860\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train = pd.read_csv(\"/Users/JoonH/dont-overfit-ii/train.csv\")\n",
    "train_y = train['target']\n",
    "train_X = train.drop(['id','target'], axis=1).values\n",
    "\n",
    "test = pd.read_csv(\"/Users/JoonH/dont-overfit-ii/test.csv\")\n",
    "test = test.drop(['id'], axis=1).values\n",
    "\n",
    "# scale using RobustScaler\n",
    "# fitting scaler on full data outperforms fitting on test_X only (+0.006 kaggle score)\n",
    "data = RobustScaler().fit_transform(np.concatenate((train_X, test), axis=0))\n",
    "train_X = data[:250]\n",
    "test = data[250:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.expand_dims(train_X,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = np.expand_dims(train_y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 300, 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_8 to have shape (1, 300) but got array with shape (300, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-96de409405f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.35\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\TF\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\TF\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\TF\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_8 to have shape (1, 300) but got array with shape (300, 1)"
     ]
    }
   ],
   "source": [
    "model.fit(x=train_x, y=train_x, validation_split = 0.35, epochs = 10, batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
