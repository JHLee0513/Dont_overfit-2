{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, while scrolling through the competition forum I ran into an interesting technique - Recursive Feature Elimination!\n",
    "So in this approach we try to implement RFE to our logistic regression model, and see how well it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from boruta import BorutaPy\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import featuretools as ft\n",
    "import json\n",
    "import ast\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "import eli5\n",
    "import gc\n",
    "gc.enable()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/Users/JoonH/dont-overfit-ii/train.csv\")\n",
    "test_df = pd.read_csv(\"/Users/JoonH/dont-overfit-ii/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop(['target','id'],axis=1)\n",
    "y_train = train_df['target']\n",
    "x_test = test_df.drop(['id'],axis=1)\n",
    "\n",
    "n_fold = 20\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise to prevent overfitting\n",
    "noise_std = 0.01\n",
    "x_train += np.random.normal(0, noise_std, x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, X_test, y, params, folds=folds, model_type='lgb', plot_feature_importance=False, averaging='usual', model=None):\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "        # print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X[train_index], X[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            train_data = lgb.Dataset(X_train, label=y_train)\n",
    "            valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "            \n",
    "            model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=2000,\n",
    "                    valid_sets = [train_data, valid_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 200)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X_tr.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X_tr.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X_tr.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_tr.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=20000,  eval_metric='AUC', **params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            # print(f'Fold {fold_n}. AUC: {score:.4f}.')\n",
    "            # print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            \n",
    "        if model_type == 'glm':\n",
    "            model = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "            model_results = model.fit()\n",
    "            model_results.predict(X_test)\n",
    "            y_pred_valid = model_results.predict(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            \n",
    "            y_pred = model_results.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(roc_auc_score(y_valid, y_pred_valid))\n",
    "\n",
    "        if averaging == 'usual':\n",
    "            prediction += y_pred\n",
    "        elif averaging == 'rank':\n",
    "            prediction += pd.Series(y_pred).rank().values  \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = X.columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_fold\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        feature_importance[\"importance\"] /= n_fold\n",
    "        if plot_feature_importance:\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "        \n",
    "            return oof, prediction, feature_importance\n",
    "        return oof, prediction, scores\n",
    "    \n",
    "    else:\n",
    "        return oof, prediction, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7144, std: 0.1206.\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr, prediction_lr, _ = train_model(x_train, x_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "selector = RFECV(model,1,20, cv=StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42),scoring='roc_auc') \n",
    "selector = selector.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 26\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Optimal number of features : %d\" % selector.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = selector.predict_proba(x_test)\n",
    "results = predictions[:,1]\n",
    "predictions = pd.DataFrame(results, columns = ['target'])\n",
    "ids = test_df['id']\n",
    "predictions = pd.concat([ids, predictions], axis = 1, sort=False)\n",
    "predictions.to_csv('dont_overfit_2_approach3_RFECV.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a LB score of 0.849"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sum bootstrapping\n",
    "\n",
    "As a followup, since this has our highest score let's try bootstrapping a bit of our prediction to generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.reset_index(drop=True, inplace=True)\n",
    "#predictions.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.693150</td>\n",
       "      <td>250</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>-1.595</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-2.628</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>2.078</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>2.132</td>\n",
       "      <td>0.609</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.462844</td>\n",
       "      <td>251</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>1.347</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.683</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.606</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>-1.133</td>\n",
       "      <td>-3.138</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.535151</td>\n",
       "      <td>252</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.509</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.835</td>\n",
       "      <td>-0.476</td>\n",
       "      <td>1.428</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.351</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-1.327</td>\n",
       "      <td>2.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.778796</td>\n",
       "      <td>253</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>-1.855</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>0.578</td>\n",
       "      <td>1.592</td>\n",
       "      <td>0.512</td>\n",
       "      <td>-1.419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.787</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>0.916</td>\n",
       "      <td>2.411</td>\n",
       "      <td>1.053</td>\n",
       "      <td>-1.601</td>\n",
       "      <td>-1.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.438243</td>\n",
       "      <td>254</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>1.173</td>\n",
       "      <td>-1.623</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.781</td>\n",
       "      <td>...</td>\n",
       "      <td>2.184</td>\n",
       "      <td>-1.090</td>\n",
       "      <td>0.216</td>\n",
       "      <td>1.186</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.322</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-1.153</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target   id      0      1      2      3      4      5      6  ...    \\\n",
       "0  250  0.693150  250  0.500 -1.033 -1.595  0.309 -0.714  0.502  0.535  ...     \n",
       "1  251  0.462844  251  0.776  0.914 -0.494  1.347 -0.867  0.480  0.578  ...     \n",
       "2  252  0.535151  252  1.750  0.509 -0.057  0.835 -0.476  1.428 -0.701  ...     \n",
       "3  253  0.778796  253 -0.556 -1.855 -0.682  0.578  1.592  0.512 -1.419  ...     \n",
       "4  254  0.438243  254  0.754 -0.245  1.173 -1.623  0.009  0.370  0.781  ...     \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0 -0.088 -2.628 -0.845  2.078 -0.277  2.132  0.609 -0.104  0.312  0.979  \n",
       "1 -0.683 -0.066  0.025  0.606 -0.353 -1.133 -3.138  0.281 -0.625 -0.761  \n",
       "2 -0.094  0.351 -0.607 -0.737 -0.031  0.701  0.976  0.135 -1.327  2.463  \n",
       "3 -0.336 -0.787  0.255 -0.031 -0.836  0.916  2.411  1.053 -1.601 -1.529  \n",
       "4  2.184 -1.090  0.216  1.186 -0.143  0.322 -0.068 -0.156 -1.153  0.825  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap = pd.concat([predictions,test_df],axis=1)\n",
    "bootstrap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def normal_round(n):\n",
    "    if n - math.floor(n) < 0.5:\n",
    "        return math.floor(n)\n",
    "    return math.ceil(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>-1.595</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-2.628</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>2.078</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>2.132</td>\n",
       "      <td>0.609</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>1.347</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.683</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.606</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>-1.133</td>\n",
       "      <td>-3.138</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.509</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.835</td>\n",
       "      <td>-0.476</td>\n",
       "      <td>1.428</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.351</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-1.327</td>\n",
       "      <td>2.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>-1.855</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>0.578</td>\n",
       "      <td>1.592</td>\n",
       "      <td>0.512</td>\n",
       "      <td>-1.419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.787</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>0.916</td>\n",
       "      <td>2.411</td>\n",
       "      <td>1.053</td>\n",
       "      <td>-1.601</td>\n",
       "      <td>-1.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>1.173</td>\n",
       "      <td>-1.623</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.781</td>\n",
       "      <td>...</td>\n",
       "      <td>2.184</td>\n",
       "      <td>-1.090</td>\n",
       "      <td>0.216</td>\n",
       "      <td>1.186</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.322</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-1.153</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  target   id      0      1      2      3      4      5      6  ...    \\\n",
       "0  250       1  250  0.500 -1.033 -1.595  0.309 -0.714  0.502  0.535  ...     \n",
       "1  251       0  251  0.776  0.914 -0.494  1.347 -0.867  0.480  0.578  ...     \n",
       "2  252       1  252  1.750  0.509 -0.057  0.835 -0.476  1.428 -0.701  ...     \n",
       "3  253       1  253 -0.556 -1.855 -0.682  0.578  1.592  0.512 -1.419  ...     \n",
       "4  254       0  254  0.754 -0.245  1.173 -1.623  0.009  0.370  0.781  ...     \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0 -0.088 -2.628 -0.845  2.078 -0.277  2.132  0.609 -0.104  0.312  0.979  \n",
       "1 -0.683 -0.066  0.025  0.606 -0.353 -1.133 -3.138  0.281 -0.625 -0.761  \n",
       "2 -0.094  0.351 -0.607 -0.737 -0.031  0.701  0.976  0.135 -1.327  2.463  \n",
       "3 -0.336 -0.787  0.255 -0.031 -0.836  0.916  2.411  1.053 -1.601 -1.529  \n",
       "4  2.184 -1.090  0.216  1.186 -0.143  0.322 -0.068 -0.156 -1.153  0.825  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap['target'] = [normal_round(x) for x in bootstrap['target']]\n",
    "bootstrap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>-1.595</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.535</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-2.628</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>2.078</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>2.132</td>\n",
       "      <td>0.609</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1.208</td>\n",
       "      <td>-2.625</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>1.182</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>1.658</td>\n",
       "      <td>-1.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541</td>\n",
       "      <td>-1.735</td>\n",
       "      <td>-1.349</td>\n",
       "      <td>-1.128</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.977</td>\n",
       "      <td>-0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.549</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-2.061</td>\n",
       "      <td>0.531</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>0.737</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.540</td>\n",
       "      <td>-0.862</td>\n",
       "      <td>0.714</td>\n",
       "      <td>1.272</td>\n",
       "      <td>-1.209</td>\n",
       "      <td>0.797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.433</td>\n",
       "      <td>-1.085</td>\n",
       "      <td>-1.455</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-0.793</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1.239</td>\n",
       "      <td>0.887</td>\n",
       "      <td>-0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>1.216</td>\n",
       "      <td>-1.062</td>\n",
       "      <td>-1.382</td>\n",
       "      <td>-1.120</td>\n",
       "      <td>-1.043</td>\n",
       "      <td>-2.030</td>\n",
       "      <td>1.948</td>\n",
       "      <td>0.539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.295</td>\n",
       "      <td>0.979</td>\n",
       "      <td>-0.897</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.523</td>\n",
       "      <td>1.275</td>\n",
       "      <td>1.191</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target      0      1      2      3      4      5      6      7      8  \\\n",
       "0        1  0.500 -1.033 -1.595  0.309 -0.714  0.502  0.535 -0.129 -0.687   \n",
       "10       1  1.208 -2.625 -0.417  1.182  0.151 -0.457 -0.080  1.658 -1.032   \n",
       "20       0  0.155  0.549 -0.368 -0.545  0.898  0.255  0.871  0.232 -0.437   \n",
       "30       0 -0.973 -0.306  0.412  0.540 -0.862  0.714  1.272 -1.209  0.797   \n",
       "40       0 -0.489  1.216 -1.062 -1.382 -1.120 -1.043 -2.030  1.948  0.539   \n",
       "\n",
       "    ...      290    291    292    293    294    295    296    297    298  \\\n",
       "0   ...   -0.088 -2.628 -0.845  2.078 -0.277  2.132  0.609 -0.104  0.312   \n",
       "10  ...    0.541 -1.735 -1.349 -1.128  1.001  0.338  0.531  0.771  0.977   \n",
       "20  ...    0.620  0.009 -2.061  0.531 -0.642 -0.671  0.737 -0.036  0.596   \n",
       "30  ...   -0.190  0.433 -1.085 -1.455  0.286 -0.793  0.353  1.239  0.887   \n",
       "40  ...    0.729  1.250  1.295  0.979 -0.897  0.344  0.523  1.275  1.191   \n",
       "\n",
       "      299  \n",
       "0   0.979  \n",
       "10 -0.822  \n",
       "20  0.422  \n",
       "30 -0.750  \n",
       "40  0.019  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap = bootstrap.drop(['id'],axis=1)\n",
    "bootstrap = bootstrap[0:100:10]\n",
    "bootstrap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.347</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-2.097</td>\n",
       "      <td>1.051</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>1.038</td>\n",
       "      <td>-1.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-1.695</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>1.359</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>-1.624</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-1.222</td>\n",
       "      <td>0.726</td>\n",
       "      <td>1.444</td>\n",
       "      <td>-1.165</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-1.637</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>-1.035</td>\n",
       "      <td>0.834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.595</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.347</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>0.511</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.594</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.134</td>\n",
       "      <td>2.415</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-1.006</td>\n",
       "      <td>1.378</td>\n",
       "      <td>1.246</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target      0      1      2      3      4      5      6      7  ...    \\\n",
       "0   0     1.0 -0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276  ...     \n",
       "1   1     0.0  1.081 -0.973 -0.383  0.326 -0.428  0.317  1.172  0.352  ...     \n",
       "2   2     1.0 -0.523 -0.089 -0.348  0.148 -0.022  0.404 -0.023 -0.172  ...     \n",
       "3   3     1.0  0.067 -0.021  0.392 -1.637 -0.446 -0.725 -1.035  0.834  ...     \n",
       "4   4     1.0  2.347 -0.831  0.511 -0.021  1.225  1.594  0.585  1.509  ...     \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0  0.867  1.347  0.504 -0.649  0.672 -2.097  1.051 -0.414  1.038 -1.065  \n",
       "1 -0.165 -1.695 -1.257  1.359 -0.808 -1.624 -0.458 -1.099 -0.936  0.973  \n",
       "2  0.013  0.263 -1.222  0.726  1.444 -1.165 -1.544  0.004  0.800 -1.211  \n",
       "3 -0.404  0.640 -0.595 -0.966  0.900  0.467 -0.562 -0.254 -0.533  0.238  \n",
       "4  0.898  0.134  2.415 -0.996 -1.006  1.378  1.246  1.478  0.428  0.253  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>-1.595</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.535</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-2.628</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>2.078</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>2.132</td>\n",
       "      <td>0.609</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.208</td>\n",
       "      <td>-2.625</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>1.182</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>1.658</td>\n",
       "      <td>-1.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541</td>\n",
       "      <td>-1.735</td>\n",
       "      <td>-1.349</td>\n",
       "      <td>-1.128</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.977</td>\n",
       "      <td>-0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.549</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-2.061</td>\n",
       "      <td>0.531</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>0.737</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.540</td>\n",
       "      <td>-0.862</td>\n",
       "      <td>0.714</td>\n",
       "      <td>1.272</td>\n",
       "      <td>-1.209</td>\n",
       "      <td>0.797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.433</td>\n",
       "      <td>-1.085</td>\n",
       "      <td>-1.455</td>\n",
       "      <td>0.286</td>\n",
       "      <td>-0.793</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1.239</td>\n",
       "      <td>0.887</td>\n",
       "      <td>-0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>1.216</td>\n",
       "      <td>-1.062</td>\n",
       "      <td>-1.382</td>\n",
       "      <td>-1.120</td>\n",
       "      <td>-1.043</td>\n",
       "      <td>-2.030</td>\n",
       "      <td>1.948</td>\n",
       "      <td>0.539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.295</td>\n",
       "      <td>0.979</td>\n",
       "      <td>-0.897</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.523</td>\n",
       "      <td>1.275</td>\n",
       "      <td>1.191</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target      0      1      2      3      4      5      6      7      8  \\\n",
       "0      1.0  0.500 -1.033 -1.595  0.309 -0.714  0.502  0.535 -0.129 -0.687   \n",
       "10     1.0  1.208 -2.625 -0.417  1.182  0.151 -0.457 -0.080  1.658 -1.032   \n",
       "20     0.0  0.155  0.549 -0.368 -0.545  0.898  0.255  0.871  0.232 -0.437   \n",
       "30     0.0 -0.973 -0.306  0.412  0.540 -0.862  0.714  1.272 -1.209  0.797   \n",
       "40     0.0 -0.489  1.216 -1.062 -1.382 -1.120 -1.043 -2.030  1.948  0.539   \n",
       "\n",
       "    ...      290    291    292    293    294    295    296    297    298  \\\n",
       "0   ...   -0.088 -2.628 -0.845  2.078 -0.277  2.132  0.609 -0.104  0.312   \n",
       "10  ...    0.541 -1.735 -1.349 -1.128  1.001  0.338  0.531  0.771  0.977   \n",
       "20  ...    0.620  0.009 -2.061  0.531 -0.642 -0.671  0.737 -0.036  0.596   \n",
       "30  ...   -0.190  0.433 -1.085 -1.455  0.286 -0.793  0.353  1.239  0.887   \n",
       "40  ...    0.729  1.250  1.295  0.979 -0.897  0.344  0.523  1.275  1.191   \n",
       "\n",
       "      299  \n",
       "0   0.979  \n",
       "10 -0.822  \n",
       "20  0.422  \n",
       "30 -0.750  \n",
       "40  0.019  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_df = pd.concat([bootstrap,train_df.drop(['id'],axis=1)],axis=0)\n",
    "comb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = comb_df.drop(['target'],axis=1)\n",
    "y_train = comb_df['target'].astype('float64')\n",
    "x_test = test_df.drop(['id'],axis=1)\n",
    "\n",
    "n_fold = 20\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(comb_df.values >= np.finfo(np.float64).max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7125, std: 0.0721.\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr, prediction_lr, _ = train_model(x_train, x_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "selector = RFECV(model,1,25, cv=StratifiedKFold(n_splits=20, shuffle=True, random_state=42),scoring='roc_auc') \n",
    "selector = selector.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 34\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Optimal number of features : %d\" % selector.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = selector.predict_proba(x_test)\n",
    "results = predictions2[:,1]\n",
    "predictions2 = pd.DataFrame(results, columns = ['target'])\n",
    "ids = test_df['id']\n",
    "predictions2 = pd.concat([ids, predictions2], axis = 1, sort=False)\n",
    "predictions2.to_csv('dont_overfit_2_approach3_RFECV+bootstrap.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.728204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.397405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0.513635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0.809781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.269461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0  250  0.728204\n",
       "1  251  0.397405\n",
       "2  252  0.513635\n",
       "3  253  0.809781\n",
       "4  254  0.269461"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't particularly help us as we get a LB score of 0.845, hmm.. seems like the model is overfitting further by introducing samples that it labelled on its own."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
