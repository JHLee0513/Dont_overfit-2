{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.enable()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 213\n",
    "np.random.seed(random_seed)\n",
    "noise_std = 0.01\n",
    "\n",
    "# import data\n",
    "train = pd.read_csv(\"/Users/JoonH/dont-overfit-ii/train.csv\")\n",
    "train_y = train['target']\n",
    "train_X = train.drop(['id','target'], axis=1).values\n",
    "\n",
    "test = pd.read_csv(\"/Users/JoonH/dont-overfit-ii/test.csv\")\n",
    "test = test.drop(['id'], axis=1).values\n",
    "\n",
    "# scale using RobustScaler\n",
    "# fitting scaler on full data outperforms fitting on test_X only (+0.006 kaggle score)\n",
    "data = RobustScaler().fit_transform(np.concatenate((train_X, test), axis=0))\n",
    "train_X = data[:250]\n",
    "test = data[250:]\n",
    "\n",
    "#scale only with respect to training data to prevent leakage\n",
    "#scaler = RobustScaler().fit(train_X)\n",
    "#train_X = scaler.transform(train_X)\n",
    "#test = scaler.transform(test)\n",
    "\n",
    "# add a bit of noise to train_X to reduce overfitting\n",
    "train_X += np.random.normal(0, noise_std, train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(300,))\n",
    "    x = Dense(64, activation=LeakyReLU(alpha = 0.1), kernel_regularizer = 'l1')(inputs)\n",
    "    x = Dropout(rate = 0.5) (x)\n",
    "    x = Dense(64, activation=LeakyReLU(alpha = 0.1), kernel_regularizer = 'l1')(inputs)\n",
    "    x = Dropout(rate = 0.5) (x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/34019\n",
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  validation loss: 0.7851362553509799, ROC_AUC: 0.8214285714285715, R2: 0.2162791598926891 <-- OK\n",
      "2  validation loss: 0.7862817482514814, ROC_AUC: 0.7762276785714286, R2: 0.17229208621111783 <-- OK\n",
      "3  validation loss: 0.799250451001254, ROC_AUC: 0.7829241071428571, R2: 0.16437530517578125 <-- OK\n",
      "4  validation loss: 0.7427422404289246, ROC_AUC: 0.8683035714285715, R2: 0.25172948295419867 <-- OK\n",
      "5  validation loss: 0.7652633569457314, ROC_AUC: 0.80859375, R2: 0.2085599357431585 <-- OK\n",
      "6  validation loss: 0.7609402699904009, ROC_AUC: 0.8169642857142857, R2: 0.1726505160331726 <-- OK\n",
      "7  validation loss: 0.7242300943894819, ROC_AUC: 0.8805803571428571, R2: 0.27306615764444525 <-- OK\n",
      "8  validation loss: 0.7711965224959634, ROC_AUC: 0.8046875, R2: 0.21149024096402255 <-- OK\n",
      "9  validation loss: 0.755522608757019, ROC_AUC: 0.8727678571428571, R2: 0.19667383215644144 <-- OK\n",
      "10  validation loss: 0.7937669537284158, ROC_AUC: 0.7700892857142858, R2: 0.1643953648480502 <-- OK\n",
      "11  validation loss: 0.7824147072705355, ROC_AUC: 0.7806919642857143, R2: 0.17799459804188122 <-- OK\n",
      "12  validation loss: 0.7488467747514899, ROC_AUC: 0.8331473214285715, R2: 0.2502087950706482 <-- OK\n",
      "13  validation loss: 0.784885823726654, ROC_AUC: 0.7801339285714286, R2: 0.1782519817352295 <-- OK\n",
      "14  validation loss: 0.7627191977067427, ROC_AUC: 0.8247767857142857, R2: 0.16745350577614523 <-- OK\n",
      "15  validation loss: 0.7760746262290261, ROC_AUC: 0.7935267857142857, R2: 0.17469099976799704 <-- OK\n",
      "16  validation loss: 0.7724194635044445, ROC_AUC: 0.7890625, R2: 0.1684747663411227 <-- OK\n",
      "17  validation loss: 0.7763225056908347, ROC_AUC: 0.8113839285714286, R2: 0.17994694818149914 <-- OK\n",
      "17 out of 20 chosen for ensemble\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "sss_n_splits = 20\n",
    "sss_test_size = 0.35\n",
    "predictions = pd.DataFrame()\n",
    "r2_threshold = 0.185\n",
    "for train_index, val_index in StratifiedShuffleSplit(n_splits=sss_n_splits, test_size=sss_test_size, random_state=random_seed).split(train_X, train_y):\n",
    "    X, val_X = train_X[train_index], train_X[val_index]\n",
    "    y, val_y = train_y[train_index], train_y[val_index]\n",
    "    K.clear_session()\n",
    "    model = get_model()\n",
    "    early = EarlyStopping(patience = 3, monitor = 'val_loss', verbose = 0)\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[r2_keras])\n",
    "    model.fit(X, y, epochs = 200, batch_size = 64, validation_data=(val_X, val_y), shuffle = True, verbose = 0, callbacks = [early])\n",
    "    \n",
    "    val_loss, val_r2 = model.evaluate(val_X, val_y, verbose=0)\n",
    "    val_y_pred = model.predict(val_X)\n",
    "    val_roc = roc_auc_score(val_y, val_y_pred)\n",
    "    \n",
    "    \n",
    "    if (val_r2 > r2_threshold):\n",
    "        counter+=1\n",
    "        print( str(counter) + \"  validation loss: \" + str(val_loss) + ', ROC_AUC: ' + str(val_roc) + ', R2: ' + str(val_r2) + ' <-- OK')\n",
    "        prediction = model.predict(test)\n",
    "        predictions = pd.concat([predictions, pd.DataFrame(prediction)], axis=1)\n",
    "        \n",
    "    #else:\n",
    "        #print(\"validation loss: \" + str(val_loss) + ' ROC_AUC: ' + str(val_roc) + 'R2: ' + str(val_r2) + ' <-- Skipping')\n",
    "        \n",
    "print(str(counter) + ' out of ' + str(sss_n_splits) + ' chosen for ensemble')\n",
    "mean_pred = pd.DataFrame(predictions.mean(axis=1))\n",
    "mean_pred.index += 250\n",
    "mean_pred.columns = ['target']\n",
    "mean_pred.to_csv('/Users/JoonH/dont_overfit2_mlp.csv', index_label='id', index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
