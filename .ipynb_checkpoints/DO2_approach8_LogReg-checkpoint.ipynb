{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving our log reg model for better improvement\n",
    "\n",
    "So we saw even blending a log reg model initially at 0.849 with lasso model of 0.868 improves at 0.869! We will see if improving our log reg score will help towards that. \n",
    "\n",
    "\n",
    "Hence, let's try implementing bayesian methods to logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoonH\\AppData\\Local\\conda\\conda\\envs\\TF\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from boruta import BorutaPy\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, r2_score, make_scorer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import theano.tensor as t\n",
    "from scipy.stats import mode\n",
    "import pymc3 as pm\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train = pd.read_csv(\"/Users/JoonH/dont-overfit-ii/train.csv\")\n",
    "train_y = train['target'].astype(int)\n",
    "train_X = train.drop(['id','target'], axis=1).values\n",
    "\n",
    "test_df = pd.read_csv(\"/Users/JoonH/dont-overfit-ii/test.csv\")\n",
    "test = test_df.drop(['id'], axis=1).values\n",
    "\n",
    "# scale using RobustScaler\n",
    "# fitting scaler on full data outperforms fitting on test_X only (+0.006 kaggle score)\n",
    "data = RobustScaler().fit_transform(np.concatenate((train_X, test), axis=0))\n",
    "#scaler = RobustScaler().fit(train_X)\n",
    "#train_X = scaler.transform(train_X)\n",
    "train_X = data[:250]\n",
    "test = data[250:]\n",
    "#test = scaler.transform(test)\n",
    "# add a bit of noise to train_X to reduce overfitting\n",
    "#train_X += np.random.normal(0, 0.01, train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BorutaPy(alpha=0.05,\n",
       "     estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=5, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=489, n_jobs=4, oob_score=False,\n",
       "            random_state=<mtrand.RandomState object at 0x00000208657F5750>,\n",
       "            verbose=0, warm_start=False),\n",
       "     max_iter=5, n_estimators='auto', perc=100,\n",
       "     random_state=<mtrand.RandomState object at 0x00000208657F5750>,\n",
       "     two_step=True, verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 200, n_jobs = 4, class_weight = 'balanced', max_depth=5)\n",
    "boruta_selector = BorutaPy(rfc, n_estimators = 'auto', verbose = 0, max_iter = 5)\n",
    "boruta_selector.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features  rank\n",
       "0       33     2\n",
       "1      217     2\n",
       "2       65     2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = pd.DataFrame(train.drop(['id','target'],axis=1).columns.tolist(),columns = ['features'])\n",
    "feature_df['rank'] = boruta_selector.ranking_\n",
    "feature_df = feature_df.sort_values('rank',ascending=True).reset_index(drop=True)\n",
    "feature_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep top 50 features\n",
    "columns_to_keep = feature_df.features[0:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>33</th>\n",
       "      <th>217</th>\n",
       "      <th>65</th>\n",
       "      <th>117</th>\n",
       "      <th>91</th>\n",
       "      <th>295</th>\n",
       "      <th>80</th>\n",
       "      <th>24</th>\n",
       "      <th>82</th>\n",
       "      <th>194</th>\n",
       "      <th>...</th>\n",
       "      <th>215</th>\n",
       "      <th>113</th>\n",
       "      <th>45</th>\n",
       "      <th>9</th>\n",
       "      <th>53</th>\n",
       "      <th>290</th>\n",
       "      <th>0</th>\n",
       "      <th>71</th>\n",
       "      <th>15</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385</td>\n",
       "      <td>1.187</td>\n",
       "      <td>-0.770</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-2.097</td>\n",
       "      <td>1.851</td>\n",
       "      <td>1.763</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.833</td>\n",
       "      <td>1.825</td>\n",
       "      <td>1.238</td>\n",
       "      <td>0.867</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>0.417</td>\n",
       "      <td>-1.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.721</td>\n",
       "      <td>0.216</td>\n",
       "      <td>1.221</td>\n",
       "      <td>0.987</td>\n",
       "      <td>1.188</td>\n",
       "      <td>-1.624</td>\n",
       "      <td>-0.759</td>\n",
       "      <td>-1.519</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-1.102</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.660</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.813</td>\n",
       "      <td>1.133</td>\n",
       "      <td>-0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.943</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-1.165</td>\n",
       "      <td>0.758</td>\n",
       "      <td>1.786</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.394</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.706</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>1.103</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.365</td>\n",
       "      <td>1.848</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>...</td>\n",
       "      <td>1.410</td>\n",
       "      <td>0.589</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.570</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-1.442</td>\n",
       "      <td>-0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.357</td>\n",
       "      <td>1.027</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.378</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.138</td>\n",
       "      <td>...</td>\n",
       "      <td>1.960</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.344</td>\n",
       "      <td>2.198</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>0.898</td>\n",
       "      <td>2.347</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.270</td>\n",
       "      <td>-1.906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      33    217     65    117     91    295     80     24     82    194  ...  \\\n",
       "0  0.385  1.187 -0.770  0.710  0.019 -2.097  1.851  1.763 -0.380 -0.226  ...   \n",
       "1 -2.721  0.216  1.221  0.987  1.188 -1.624 -0.759 -1.519  0.406  0.083  ...   \n",
       "2  0.924  0.269  0.943 -0.384  0.269 -1.165  0.758  1.786 -0.101 -0.500  ...   \n",
       "3  0.394  0.066 -0.706 -0.152  1.103  0.467  0.030  0.365  1.848 -0.902  ...   \n",
       "4  0.037  0.110  0.357  1.027  0.892  1.378 -0.187  0.024 -0.054  0.138  ...   \n",
       "\n",
       "     215    113     45      9     53    290      0     71     15     90  \n",
       "0  0.817  0.405  0.833  1.825  1.238  0.867 -0.098 -0.974  0.417 -1.675  \n",
       "1  0.329 -0.178 -1.102 -0.291  0.660 -0.165  1.081 -0.813  1.133 -0.030  \n",
       "2  0.307 -0.275  0.972  0.183 -0.714  0.013 -0.523  0.409  0.300  0.696  \n",
       "3  1.410  0.589 -0.861  0.274  0.570 -0.404  0.067  0.205 -1.442 -0.604  \n",
       "4  1.960  0.011  0.344  2.198 -0.312  0.898  2.347  0.732  0.270 -1.906  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boruta_train = train[columns_to_keep]\n",
    "boruta_test = test_df[columns_to_keep]\n",
    "boruta_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale using RobustScaler\n",
    "# fitting scaler on full data outperforms fitting on test_X only (+0.006 kaggle score)\n",
    "data = RobustScaler().fit_transform(np.concatenate((boruta_train, boruta_test), axis=0))\n",
    "train_X = data[:250]\n",
    "test = data[250:]\n",
    "# add a bit of noise to train_X to reduce overfitting\n",
    "train_X += np.random.normal(0, 0.01, train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_3ff3dda648840fef960ca7e40a266ea9 NOW.\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/gkoundry/bayesian-logistic-regression-with-pystan                                                                                                     \n",
    "code = \"\"\"                                                                                           \n",
    "data {                                                                                               \n",
    "  int N; //the number of training observations                                                       \n",
    "  int N2; //the number of test observations                                                          \n",
    "  int K; //the number of features                                                                    \n",
    "  int y[N]; //the response                                                                           \n",
    "  matrix[N,K] X; //the model matrix                                                                  \n",
    "  matrix[N2,K] new_X; //the matrix for the predicted values                                          \n",
    "}                                                                                                    \n",
    "parameters {                                                                                         \n",
    "  real alpha;                                                                                        \n",
    "  vector[K] beta; //the regression parameters                                                        \n",
    "}                                                                                                    \n",
    "transformed parameters {                                                                             \n",
    "  vector[N] linpred;                                                                                 \n",
    "  linpred = alpha+X*beta;                                                                            \n",
    "}                                                                                                    \n",
    "model {                                                                                              \n",
    "  alpha ~ cauchy(0,10); //prior for the intercept following Gelman 2008                              \n",
    "                                                                                                     \n",
    "  for(i in 1:K)                                                                                      \n",
    "    beta[i] ~ student_t(1, 0, 0.03);                                                                 \n",
    "                                                                                                     \n",
    "  y ~ bernoulli_logit(linpred);                                                                      \n",
    "}                                                                                                    \n",
    "generated quantities {                                                                               \n",
    "  vector[N2] y_pred;                                                                                 \n",
    "  y_pred = alpha+new_X*beta; //the y values predicted by the model                                   \n",
    "}                                                                                                    \n",
    "\"\"\"    \n",
    "\n",
    "data = {                                                                                             \n",
    "    'N': 250,                                                                                        \n",
    "    'N2': 19750,                                                                                     \n",
    "    'K': 80,                                                                                        \n",
    "    'y': train_y,                                                                                     \n",
    "    'X': train_X,                                                                                      \n",
    "    'new_X': test,                                                                                   \n",
    "} \n",
    "\n",
    "n_itr = 3000\n",
    "n_warmup = 1000\n",
    "\n",
    "sm = pystan.StanModel(model_code = code)\n",
    "fit = sm.sampling(data = data, iter = n_itr, warmup = n_warmup, seed = None)\n",
    "ex = fit.extract(permuted = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_to_prob(logit):\n",
    "    odds = np.exp(logit)\n",
    "    prob = odds / (1 + odds)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = np.mean(ex['y_pred'], axis = 0)\n",
    "target = np.mean(logit_to_prob(ex['y_pred']), axis = 0)\n",
    "ids = test_df['id']\n",
    "df = pd.DataFrame({'id': ids, 'target' : target})\n",
    "df[['id', 'target']].to_csv(\"/Users/JoonH/DO2_pystan_log.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us LB score of 0.858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/gkoundry/bayesian-logistic-regression-with-pystan/log\n",
    "https://barnesanalytics.com/bayesian-logistic-regression-in-python-using-pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
