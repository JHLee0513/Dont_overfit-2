{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2\n",
    "\n",
    "In our first approach we have seen the influence of data's dimensionality to model performance. Here we try to perform feature selection process to improve our logstic regression model via boruta.\n",
    "\n",
    "## What is Boruta?\n",
    "Feature selection with the Boruta algorithm. Boruta is an all relevant feature selection wrapper algorithm, capable of working with any classification method that output variable importance measure (VIM); by default, Boruta uses Random Forest.\n",
    "\n",
    "https://www.datasciencecentral.com/profiles/blogs/select-important-variables-using-boruta-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, here we do the following:\n",
    "1. Train logistic regression model\n",
    "2. Perform boruta\n",
    "3. Retrain with boruta\n",
    "4. Make our final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from boruta import BorutaPy\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "gc.enable()\n",
    "gc.collect()\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/Users/JoonH/dont-overfit-ii/train.csv\")\n",
    "test_df = pd.read_csv(\"/Users/JoonH/dont-overfit-ii/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop(['target','id'],axis=1)\n",
    "y_train = train_df['target']\n",
    "x_test = test_df.drop(['id'],axis=1)\n",
    "\n",
    "n_fold = 20\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, X_test, y, params, folds=folds, model_type='lgb', plot_feature_importance=False, averaging='usual', model=None):\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "        # print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X[train_index], X[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            train_data = lgb.Dataset(X_train, label=y_train)\n",
    "            valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "            \n",
    "            model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=2000,\n",
    "                    valid_sets = [train_data, valid_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 200)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X_tr.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X_tr.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X_tr.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_tr.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=20000,  eval_metric='AUC', **params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            # print(f'Fold {fold_n}. AUC: {score:.4f}.')\n",
    "            # print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            \n",
    "        if model_type == 'glm':\n",
    "            model = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "            model_results = model.fit()\n",
    "            model_results.predict(X_test)\n",
    "            y_pred_valid = model_results.predict(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            \n",
    "            y_pred = model_results.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(roc_auc_score(y_valid, y_pred_valid))\n",
    "\n",
    "        if averaging == 'usual':\n",
    "            prediction += y_pred\n",
    "        elif averaging == 'rank':\n",
    "            prediction += pd.Series(y_pred).rank().values  \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = X.columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_fold\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        feature_importance[\"importance\"] /= n_fold\n",
    "        if plot_feature_importance:\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "        \n",
    "            return oof, prediction, feature_importance\n",
    "        return oof, prediction, scores\n",
    "    \n",
    "    else:\n",
    "        return oof, prediction, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7269, std: 0.0868.\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.075, solver='liblinear')\n",
    "oof_lr, prediction_lr, _ = train_model(x_train, x_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try submitting this\n",
    "results = prediction_lr\n",
    "predictions = pd.DataFrame(results, columns = ['target'])\n",
    "ids = test_df['id']\n",
    "predictions = pd.concat([ids, predictions], axis = 1, sort=False)\n",
    "predictions.to_csv('DO2_approach2_log1.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use a RandomForest model to implement feature selection via Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BorutaPy(alpha=0.05,\n",
       "     estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=5, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=489, n_jobs=4, oob_score=False,\n",
       "            random_state=<mtrand.RandomState object at 0x0000014E6E8B9F78>,\n",
       "            verbose=0, warm_start=False),\n",
       "     max_iter=5, n_estimators='auto', perc=100,\n",
       "     random_state=<mtrand.RandomState object at 0x0000014E6E8B9F78>,\n",
       "     two_step=True, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 200, n_jobs = 4, class_weight = 'balanced', max_depth=5)\n",
    "boruta_selector = BorutaPy(rfc, n_estimators = 'auto', verbose = 0, max_iter = 5)\n",
    "boruta_selector.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features  rank\n",
       "0       65     2\n",
       "1      117     2\n",
       "2       33     2\n",
       "3       91     2\n",
       "4      217     3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = pd.DataFrame(train_df.drop(['id','target'],axis=1).columns.tolist(),columns = ['features'])\n",
    "feature_df['rank'] = boruta_selector.ranking_\n",
    "feature_df = feature_df.sort_values('rank',ascending=True).reset_index(drop=True)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep top 50 features\n",
    "columns_to_keep = feature_df.features[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta_train = train_df[columns_to_keep]\n",
    "boruta_test = test_df[columns_to_keep]\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(boruta_train)\n",
    "x_test = scaler.transform(boruta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7681, std: 0.0909.\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "oof_lr, prediction_lr, _ = train_model(x_train, x_test, y_train, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = prediction_lr\n",
    "predictions = pd.DataFrame(results, columns = ['target'])\n",
    "ids = test_df['id']\n",
    "predictions = pd.concat([ids, predictions], axis = 1, sort=False)\n",
    "predictions.to_csv('dont_overfit_2_approach2.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us 0.847 on the leaderboard. Nice! Let's see how reducing/increasing the dimensionality affects us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_features(num):\n",
    "    columns_to_keep = feature_df.features[0:num]\n",
    "    boruta_train = train_df[columns_to_keep]\n",
    "    boruta_test = test_df[columns_to_keep]\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(boruta_train)\n",
    "    x_test = scaler.transform(boruta_test)\n",
    "    model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "    oof_lr, prediction_lr, scores = train_model(x_train, x_test, y_train, params=None, model_type='sklearn', model=model)\n",
    "    return prediction_lr, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7669, std: 0.1031.\n",
      "CV mean score: 0.7506, std: 0.0761.\n",
      "CV mean score: 0.7662, std: 0.0777.\n",
      "CV mean score: 0.7681, std: 0.0769.\n"
     ]
    }
   ],
   "source": [
    "error_scores = []\n",
    "\n",
    "for i in range(10,50,10):\n",
    "    _,scores = train_with_features(i)\n",
    "    #print(str(i) + \" features=>  \" +'CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    error_scores.append(np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.scatter(range(10,50,10), error_scores)\n",
    "fig.suptitle('Analysis of # features and std error', fontsize=20)\n",
    "plt.xlabel('number of features', fontsize=8)\n",
    "plt.ylabel('Standard error', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as we reduce the dimensionality of top K features to keep, we see an increase in accuracy and standard error. While the CV shows us its average performance over our data set, the std, or standard error, shows us how far away the data points are from the regression line.\n",
    "\n",
    "This means as we reduce the dimensionality, the hyperplane the model needs to locate to create a decision boundary becomes easier, but as we are relying on less features we are also becoming prone to overfitting. E.g. we may be forcing the model to focus on very specific features to classify, thus failing to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, X_test, y, params, folds=folds, model_type='lgb', plot_feature_importance=False, averaging='usual', model=None):\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "        # print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X[train_index], X[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            train_data = lgb.Dataset(X_train, label=y_train)\n",
    "            valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "            \n",
    "            model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=2000,\n",
    "                    valid_sets = [train_data, valid_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 200)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X_tr.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X_tr.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X_tr.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_tr.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=20000,  eval_metric='AUC', **params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            # print(f'Fold {fold_n}. AUC: {score:.4f}.')\n",
    "            # print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            \n",
    "        if model_type == 'glm':\n",
    "            model = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "            model_results = model.fit()\n",
    "            model_results.predict(X_test)\n",
    "            y_pred_valid = model_results.predict(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            \n",
    "            y_pred = model_results.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(roc_auc_score(y_valid, y_pred_valid))\n",
    "\n",
    "        if averaging == 'usual':\n",
    "            prediction += y_pred\n",
    "        elif averaging == 'rank':\n",
    "            prediction += pd.Series(y_pred).rank().values  \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = X.columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_fold\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        feature_importance[\"importance\"] /= n_fold\n",
    "        if plot_feature_importance:\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "        \n",
    "            return oof, prediction, feature_importance\n",
    "        return oof, prediction, scores\n",
    "    \n",
    "    else:\n",
    "        return oof, prediction, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7631, std: 0.0649.\n"
     ]
    }
   ],
   "source": [
    "results,_ = train_with_features(23)\n",
    "predictions = pd.DataFrame(results, columns = ['target'])\n",
    "ids = test_df['id']\n",
    "predictions = pd.concat([ids, predictions], axis = 1, sort=False)\n",
    "predictions.to_csv('dont_overfit_2_approach2_23_features.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this gives us a LB score of 0.846. This seems to tell us that reduction of dimensionality while maintaining the most important features help us train better in our validation, but does not necessarily help generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reduced_feat(num, model):\n",
    "    columns_to_keep = feature_df.features[0:num]\n",
    "    boruta_train = train_df[columns_to_keep]\n",
    "    boruta_test = test_df[columns_to_keep]\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(boruta_train)\n",
    "    x_test = scaler.transform(boruta_test)\n",
    "    oof_lr, prediction_lr, scores = train_model(x_train, x_test, y_train, params=None, model_type='sklearn', model=model)\n",
    "    return prediction_lr, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.7631, std: 0.0649.\n"
     ]
    }
   ],
   "source": [
    "log = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "pred_log, _ = train_reduced_feat(23, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
